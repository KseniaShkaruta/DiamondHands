{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=HW3-Q1, master=local[*]) created by __init__ at <ipython-input-2-143324fee1cf>:1 ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-208-125492b70dc6>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0msc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpyspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSparkContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mappName\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"Group Project\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0msqlContext\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSQLContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/context.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001B[0m\n\u001B[1;32m    131\u001B[0m                 \" is not allowed as it is a security risk.\")\n\u001B[1;32m    132\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 133\u001B[0;31m         \u001B[0mSparkContext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_ensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgateway\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mgateway\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconf\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    134\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    135\u001B[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/context.py\u001B[0m in \u001B[0;36m_ensure_initialized\u001B[0;34m(cls, instance, gateway, conf)\u001B[0m\n\u001B[1;32m    339\u001B[0m                         \u001B[0;34m\" created by %s at %s:%s \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    340\u001B[0m                         % (currentAppName, currentMaster,\n\u001B[0;32m--> 341\u001B[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001B[0m\u001B[1;32m    342\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    343\u001B[0m                     \u001B[0mSparkContext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_active_spark_context\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minstance\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=HW3-Q1, master=local[*]) created by __init__ at <ipython-input-2-143324fee1cf>:1 "
     ]
    }
   ],
   "source": [
    "sc = pyspark.SparkContext(appName=\"Group Project\")\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    comments_df = sqlContext.read.option(\"header\",True).csv(\"comments.csv\")\n",
    "    posts_df = sqlContext.read.option(\"header\",True).csv(\"posts.csv\")\n",
    "    comments_df = comments_df.withColumn(\"score\", comments_df[\"score\"].cast(\"integer\"))\\\n",
    "        .withColumn(\"timestamp\", comments_df[\"timestamp\"].cast(\"timestamp\"))\n",
    "    posts_df = posts_df.withColumn(\"score\", posts_df[\"score\"].cast(\"integer\"))\\\n",
    "        .withColumn(\"timestamp\", posts_df[\"timestamp\"].cast(\"timestamp\"))\n",
    "        \n",
    "    return comments_df, posts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- score: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- link_id: string (nullable = true)\n",
      " |-- parent_id: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- score: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- link_id: string (nullable = true)\n",
      " |-- parent_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comments_df, posts_df = load_data()\n",
    "comments_df.printSchema()\n",
    "posts_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comments_data(comments_df):\n",
    "    comments_df.createOrReplaceTempView(\"DATA\")\n",
    "    cleaned_comments_df = sqlContext.sql(\"SELECT * FROM DATA where text is not NULL AND text != '[removed]' AND text != '' AND text != '[deleted]'\")\n",
    "    return cleaned_comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1156394\n",
      "816290\n"
     ]
    }
   ],
   "source": [
    "print(comments_df.count())\n",
    "cleaned_comments_df = clean_comments_data(comments_df)\n",
    "print(cleaned_comments_df.count())\n",
    "cleaned_comments_df.write.csv(\"cleaned_comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_posts_data(posts_df):\n",
    "    posts_df.createOrReplaceTempView(\"DATA\")\n",
    "    cleaned_posts_df = sqlContext.sql(\"SELECT * FROM DATA where text is not NULL AND text != '[removed]' AND text != '' AND text != '[deleted]'\")\n",
    "    return cleaned_posts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892719\n",
      "135044\n"
     ]
    }
   ],
   "source": [
    "print(posts_df.count())\n",
    "cleaned_posts_df = clean_posts_data(posts_df)\n",
    "print(cleaned_posts_df.count())\n",
    "cleaned_posts_df.write.csv(\"cleaned_posts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}